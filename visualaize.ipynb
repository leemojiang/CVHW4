{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from unet import UNet\n",
    "from data_vis import plot_img_and_mask\n",
    "from dataset import BasicDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_image(mask):\n",
    "    return Image.fromarray((mask * 255).astype(np.uint8))\n",
    "\n",
    "def predict_img(net,\n",
    "                full_img,\n",
    "                device,\n",
    "                scale_factor=0.3,\n",
    "                out_threshold=0.5):\n",
    "    net.eval()\n",
    "\n",
    "    img = torch.from_numpy(BasicDataset.preprocess(full_img, scale_factor))\n",
    "\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(img)\n",
    "    output = output.squeeze(0)\n",
    "    tf = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage()\n",
    "                # transforms.Resize(full_img.size[1]),\n",
    "                # transforms.ToTensor()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    output = tf(output.cpu())\n",
    "    return output\n",
    "def mask_to_image(mask):\n",
    "    return Image.fromarray((mask * 255))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,80):\n",
    "    PREFIX=\"01\"\n",
    "    MODELDIR=\"/root/depthEstima/Demo/pytorch-nyuv2/checkpoints/CP_epoch{}.pth\".format(i)\n",
    "    IMGPATH=\"./0017.png\"\n",
    "    net = UNet(n_channels=3, n_classes=1)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    net.to(device=device)\n",
    "    net.load_state_dict(torch.load(MODELDIR, map_location=device))\n",
    "\n",
    "    img = Image.open(IMGPATH)\n",
    "    img.show()\n",
    "    outPut = predict_img(net=net,\n",
    "                            full_img=img,\n",
    "                            scale_factor=0.3,\n",
    "                            out_threshold=1,\n",
    "                            device=device)\n",
    "    outPut.save(\"./outTest/{}_{}.png\".format(PREFIX,i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}